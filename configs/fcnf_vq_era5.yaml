data:
  dataset_name: "shear_flow"
  data_dir: "/storage/zhao/thewell/datasets"
  masking_strategy: "complement"
  encoder_point_ratio: 0.5
  downsample_factor: 2

model:
  coord_features: 2
  field_features: 1
  latent_features: 512
  encoder_num_hidden_layers: 6
  encoder_hidden_features: 256
  decoder_num_hidden_layers: 3
  decoder_hidden_features: 256
  encoder_omega_0: 30
  decoder_omega_0: 30
  rank: 16
  quantizer_cfg:
    # type: "FSQ"
    dim: 512
    levels: [7,5,5,5,5]
    num_codebooks: 96
    keep_num_codebooks_dim: True
    return_indices: True

training:
  learning_rate: 1e-4
  weight_decay: 1e-2
  batch_size: 256
  max_steps: 300000
  warmup_steps: 100
  check_val_every_n_epoch: 10
  save_every_n_train_steps: 10000
  seed: 42
  num_workers: 4
  accelerator: "gpu"
  devices: 4
  strategy: "auto"
  precision: "32"
  gradient_clip_val: 1.0
  accumulate_grad_batches: 1
  beta: 0.000
  use_lipschitz: True
  lipschitz_coeff: 1e-2

logging:
  project: "ShearFlow"
  entity: "isfengzhao-cornell-university"
  # save_every_n_steps: 5000
  # checkpoint_every_n_steps: 5000 
  output_dir: "checkpoints"


# huggingface:
#   push_to_hub: false
#   repo_name: "zebra-vqvae1d"
#   private: true
#   commit_message: "Add VQVAE1D tokenizer"
#   model_card: "tokenizer_model_card.md"
#   model_card_template: "tokenizer_model_card.md"
